==============================
Using Chapel on a Cray XE (TM)
==============================

The following information is assembled to help users get up and
running on multiple nodes of a Cray XE running the Cray Linux
Environment (TM) (CLE).  If you are not familiar with Chapel, it is
recommended that you try the instructions in the top-level README
first to get started with the language.

Chapel is available as a module for Cray XE running CLE.  When it is
installed on your system, you do not need to build the compiler.
Simply load the module with:

     module load chapel

then proceed directly to compiling your Chapel programs (Step 10 below).
For information on obtaining and installing the Chapel module
please contact your system administrator.


1) Set CHPL_HOME and MANPATH as indicated in README.chplenv.


2) Set CHPL_HOST_PLATFORM to xe-cle and CHPL_COMM to gasnet.
   For example:

     setenv CHPL_HOST_PLATFORM xe-cle
     setenv CHPL_COMM gasnet

   See README.multilocale for further information about running using
   multiple locales and GASNet.


3) If your Cray XE requires PBS/qsub to launch jobs onto the compute
   nodes (or you simply want to use it as your job launch mechanism),
   set CHPL_LAUNCHER to 'pbs-aprun'.  For example:

     setenv CHPL_LAUNCHER pbs-aprun

   If it only requires aprun to launch a job, set it to 'aprun'.  If
   you want to manage all job queueing/launching responsibilities
   yourself, set it to 'none'.  If left unset, the value of
   CHPL_LAUNCHER will be set automatically to one of the three
   settings above depending on the presence of aprun and/or qsub.  See
   $CHPL_HOME/doc/README.launcher for more information on Chapel's
   launcher capabilities.


4) When using CHPL_LAUNCHER == pbs-aprun, you can optionally specify a
   queue name using the environment variable CHPL_LAUNCHER_QUEUE.  For
   example:

     setenv CHPL_LAUNCHER_QUEUE batch

   If this variable is left unset, no queue name will be specified.
   You can also optionally set a wall clock time limit for the job
   using CHPL_LAUNCHER_WALLTIME.  For example to specify a 10-minute
   time limit, use:

     setenv CHPL_LAUNCHER_WALLTIME 00:10:00


5) Ensure that you have one of the following Programming Environment
   modules loaded which will specify the C compiler used to compile
   Chapel programs for the compute nodes:

     - PrgEnv-cray
     - PrgEnv-gnu
     - PrgEnv-intel
     - PrgEnv-pgi


6) By default, g++ will be used to compile code that runs on the login
   nodes, such as the Chapel compiler and launcher code.  Optionally,
   you can override this default by setting CHPL_HOST_COMPILER to one
   of the following values:

     gnu       : the GNU compiler suite -- gcc and g++
     cray      : the Cray compiler suite -- cc and CC
     intel     : the Intel compiler suite -- icc and icpc
     pgi       : the PGI compiler suite -- pgcc and pgCC


7) Make sure you're in the top-level chapel/ directory:

     cd $CHPL_HOME

   Make/re-make the compiler and runtime:

     gmake


8) Set your PATH to include the directory $CHPL_HOME/bin/xe-cle
   which is created when you build the compiler.  For example:

     setenv PATH "$PATH":"$CHPL_HOME/bin/xe-cle"


9)  Compile your Chapel program as usual.  See README.compiling for
    details.  For example:

      chpl -o hello6-taskpar-dist $CHPL_HOME/examples/hello6-taskpar-dist.chpl


10) When you compile a Chapel program for the Cray XE, you should see
    two binaries (e.g., hello6-taskpar-dist and hello6-taskpar-dist_real).
    The first binary contains code to launch the Chapel program onto the
    compute nodes, as specified by your CHPL_LAUNCHER setting.  The
    second contains the program code itself; it is not intended to be
    executed directly from the shell prompt.


11) Multi-locale executions require the number of locales to be
    specified on the command line.  Other than this, execute your
    Chapel program as usual.  For example:

      ./hello6-taskpar-dist -nl 2

   You can use the -v flag to see the commands used to launch your
   program.  See README.launcher for further details.


12) If your Cray XE has compute nodes with varying numbers of cores,
    you can request nodes with at least a certain number of cores
    using the variable CHPL_LAUNCHER_CORES_PER_LOCALE.  For example,
    to request nodes with at least 24 cores, you might use:

      setenv CHPL_LAUNCHER_CORES_PER_LOCALE 24


-----------------------------------------
Cray XE File Systems and Chapel execution
-----------------------------------------

* For best results, it is recommended that you execute your Chapel
  program on a Lustre file system for the Cray XE, as this will
  provide the greatest amount of transparency between the login nodes
  and compute nodes.  In some cases, running a Chapel program from a
  non-Lustre file system will make it impossible to launch onto the
  compute nodes.  In other cases, the launch will succeed, but any
  files read or written by the Chapel program will opened relative to
  the compute node's file system rather than the login node's.  To
  avoid wrestling with such issues, we recommend executing Chapel
  programs from a Lustre file system directory.


--------------------------
Known Constraints and Bugs
--------------------------

* GASNet targets multiple "conduits" as the underlying communication
  mechanism.  By default, the Chapel build will use the 'mpi' conduit.
  The current version of GASNet shipped with Chapel also supports a
  beta implementation of the native gemini conduit, but it should be
  noted that this version has not been tuned.  To use the native
  conduit, set the environment variable CHPL_COMM_SUBSTRATE to
  'gemini'.  The GASNet layer prints out a warning message regarding
  the beta nature of the release.  To quiet this message set the
  environment variable CHPL_GASNET_QUIET=y.

  There is a known GASNet configuration issue when using the gemini
  conduit with hugepage support that results in link errors due to
  multiply defined symbols in the hugetlbfs library.  The workaround
  is to redefine the "post link" options environment variable set by
  the hugepages module.  The name of the environment variable contains
  POST_LINK_OPTS and will vary depending on the hugepage module that
  is loaded.  For example, if you execute 'module load
  craype-hugepages2M' and then 'module show craype-hugepages2M', it
  will show you that the variable HUGETLB2M_POST_LINK_OPTS is set.
  Redefine the post link options to be the same string except removing
  "-Wl,--whole-archive,-lhugetlbfs,--no-whole-archive".  These options
  should be consecutive and are usually first in the list of options.
  If you have any questions or problems, please contact us for help.

* Redirecting stdin when executing a Chapel program under PBS/qsub
  may not work due to limitations of qsub.
